\documentclass[
  man,
  floatsintext,
  longtable,
  nolmodern,
  notxfonts,
  notimes,
  colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{apa7}

\usepackage{amsmath}
\usepackage{amssymb}




\RequirePackage{longtable}
\RequirePackage{threeparttablex}

\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-.5em}%
	{\normalfont\normalsize\bfseries\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{0.5em}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-\z@\relax}%
	{\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother




\usepackage{longtable, booktabs, multirow, multicol, colortbl, hhline, caption, array, float, xpatch}
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.7}

\usepackage{tcolorbox}
\tcbuselibrary{listings,theorems, breakable, skins}
\usepackage{fontawesome5}

\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{ACACAC}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582EC}
\definecolor{quarto-callout-important-color-frame}{HTML}{D9534F}
\definecolor{quarto-callout-warning-color-frame}{HTML}{F0AD4E}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02B875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{FD7E14}

%\newlength\Oldarrayrulewidth
%\newlength\Oldtabcolsep


\usepackage{hyperref}



\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}

\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}


\usepackage[nolongtablepatch]{lineno}
\linenumbers



\usepackage{newtx}

\defaultfontfeatures{Scale=MatchLowercase}
\defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}





\title{eyetools: an R package for simplified analysis of eye data}


\shorttitle{eyetools: eye data analysis}


\usepackage{etoolbox}








\authorsnames{Tom Beesley,Matthew Ivory}





\affiliation{
{Lancaster University}}




\leftheader{Beesley and Ivory}



\abstract{This tutorial is designed for scientists either experienced
in, or interested in, using eye tracking who are wishing to construct
reproducible analysis pipelines in R. We begin by framing the necessity
for the development of software packages for this purpose before
introducing the eyetools R package. This is followed by demonstrations
of cleaning and repairing raw data ready for event-related processing.
Event-related processing is enabled through functions to detect
fixations, saccades, as well as time spent in Areas of Interest.
Finally, plotting functions are shown. This is followed by a brief
example of how to apply inferential statistics towards the processed
data. In offering this walkthrough of starting with (relatively) raw eye
gaze data before cleaning and processing the data to condense large
amounts of data into event-based datasets, we offer eyetools as a
toolkit for enabling easier, standardised processing pipelines. eyetools
provides a solution to improving reproducible research within eye
tracking fields. Finally, we discuss the\ldots{}}

\keywords{eye-tracking; fixations; saccades; areas-of-interest}

\authornote{\par{\addORCIDlink{Tom Beesley}{0000-0003-2836-2743}} 

\par{       }
\par{Correspondence concerning this article should be addressed to Tom
Beesley, Lancaster University, Department of Psychology, Lancaster
University, UK, LA1 4YD, UK, Email: t.beesley@lancaster.ac.uk}
}

\makeatletter
\let\endoldlt\endlongtable
\def\endlongtable{
\hline
\endoldlt
}
\makeatother

\urlstyle{same}



\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
\DefineVerbatimEnvironment{OutputCode}{Verbatim}{breaklines,commandchars=\\\{\}}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\makeatother

% From https://tex.stackexchange.com/a/645996/211326
%%% apa7 doesn't want to add appendix section titles in the toc
%%% let's make it do it
\makeatletter
\xpatchcmd{\appendix}
  {\par}
  {\addcontentsline{toc}{section}{\@currentlabelname}\par}
  {}{}
\makeatother

%% Disable longtable counter
%% https://tex.stackexchange.com/a/248395/211326

\usepackage{etoolbox}

\makeatletter
\patchcmd{\LT@caption}
  {\bgroup}
  {\bgroup\global\LTpatch@captiontrue}
  {}{}
\patchcmd{\longtable}
  {\par}
  {\par\global\LTpatch@captionfalse}
  {}{}
\apptocmd{\endlongtable}
  {\ifLTpatch@caption\else\addtocounter{table}{-1}\fi}
  {}{}
\newif\ifLTpatch@caption
\makeatother

\begin{document}

\maketitle


\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\setlength\LTleft{0pt}

\resetlinenumber[1]

Eye tracking is now an established and widely used technique in the
behavioural sciences. Perhaps the scientific discipline with the most
invested interest in eye-data is Psychology, where eye-tracking systems
are now commonplace in almost all university departments. Beyond
academic institutions, eye-tracking continues to be a useful tool in
understanding consumer behaviour, user-interface design, and in various
forms of entertainment.

By recording the movement of an individual's gaze during research
studies, researchers can quantify where and how long individual's look
at particular regions of space (usually with a focus on stimuli
presented on a 2D screen, but also within 3D space). Eye tracking
provides a rich stream of continuous data and therefore can offer
powerful insights into real-time cognitive processing. Such data allow
researchers to inspect the interplay of cognitive processes such as
attention, memory, and decision making, with high temporal precision
(\citeproc{ref-duchowski2017eye}{Duchowski \& Duchowski, 2017}).

While there are abundant uses and benefits of collecting eye-movement
data in psychology experiments, the continual stream of recording can
lead to an overwhelming amount of raw data: modern eye-trackers can
record data at 1000 Hz and above, which results in 3.6 million rows of
data per hour. The provision of suitable computational software for data
reduction and processing is an important part of eye-tracking research.
The companies behind eye-tracking devices offer licensed software that
will perform many of the necessary steps for eye-data analysis. However,
there are several disadvantages to using such proprietary software in a
research context. Firstly, the software will typically have an ongoing
(annual) license cost for continual use. Secondly, the algorithms
driving the operations within such software are not readily available
for inspection. Both of these important constraints mean that the use of
proprietary analysis software will lead to a failure to meet the basic
open-science principle of analysis reproduction, for example as set out
by the UK Reproducibility Network: ``We expect researchers to\ldots{}
make their research methods, software, outputs and data open, and
available at the earliest possible point\ldots The reproducibility of
both research methods and research results \ldots is critical to
research in certain contexts, particularly in the experimental sciences
with a quantitative focus\ldots{}''

In the current article we introduce a new toolkit for eye-data
processing and analysis called ``\emph{eyetools}'', which takes the form
of an R package. R packages (like R itself) are free to use without
licence and are therefore available for any user across the world. The
package provides a (growing) number of functions that provide an
efficient and effective means to conduct basic eye-data analysis.
\emph{eyetools} is built with academic researchers in the psychological
sciences in mind, though there is no reason why the package would not be
effective more generally. The functions within the package reflect steps
in a comprehensive analysis workflow, taking the user from initial
handling of raw eye data, to summarising data for each period of a
procedure, to the visualisation of the data in plots. We hope that the
functions are simple enough to mean that the package is easy to use for
researchers who are unfamiliar with working with eye data. It should
also appeal to researchers accustomed to working with eye data in other
environments who wish to transfer to working in R.

One benefit of adopting the R environment for research purposes is that
there is an active community of users who are continuously developing
and improving functions that help to streamline data processing and
analysis. With this, if a certain processing step or analytical method
is presently unavailable, one can either contribute these functions
oneself, or requests can be made to other members of the community to
provide these functions. The continued development of the
\emph{eyetools} package means that it does not necessarily represent a
static entity and instead is a constantly growing collection of
processes that help to ease the burden of data analysis. As more
processes are identified within a research pipeline that represent a
``reproducible'' and ``repeatable'' component, these can be standardised
and incorporated into packages such as \emph{eyetools}. It is important
to stress that \emph{eyetools} is not a completed project, and that
contributions and suggestions from the wider community will only help to
improve it.

\emph{eyetools} is, of course, not the only package in R that allows
users to work with eye data. A recent assessment of available packages
on CRAN identified six other packages that offer relevant functions for
the analysis of eye data. \textbf{eyeTrackr}, \textbf{eyelinker}, and
\textbf{eyelinkReader}, all offer functionality for data only from
experiments that have used `EyeLink' trackers (S-R Research). In
contrast, eyetools provides functions that are hardware-agnostic,
relying on a format of data that can be achieved from any data source.
The \textbf{eyeRead} package is designed for the analysis of eye data
from reading exercises. The \textbf{emov} package offers a limited set
of functions and is primarily designed for fixation detection, using the
same dispersion algorithm used in eyetools. Finally,
\textbf{eyetrackingR} is perhaps the most comprehensive alternative
package available on CRAN. eyetrackingR offers a large suite of
functionality and, like eyetools, can be applied across the entire
pipeline. It has functions for cleaning data and various plotting
functions, including analysis over time. It does not feature algorithms
regarding the detection of events such as saccades or fixations. This
limits the ability to conduct more bespoke and dataset specific
processing or analysis steps. In comparison, eyetools enables easier
data processing up to data analyses, making core tasks in the eye data
processing easier and standardised. Table~\ref{tbl-comparison}
highlights the key differences between the available packages.

\begin{table}

{\caption{{A comparison of the functionality available in the available
CRAN packages for eye data. * for Tobii data only, ** for text reading
experiments only}{\label{tbl-comparison}}}
\vspace{-20pt}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1087}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1377}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1739}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1304}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1594}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1304}}
  >{\centering\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1594}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Package
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Hardware-agnostic
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Data Importing
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Data processing
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Identifies events
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Plotting
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Inferential Analysis
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
eyetools & \faIcon{check} & \faIcon{check}* & \faIcon{check} &
\faIcon{check} & \faIcon{check} & \\
eyeTrackr & & \faIcon{check} & \faIcon{check} & \faIcon{check} & & \\
eyelinker & & \faIcon{check} & & & & \\
eyelinkReader & & \faIcon{check} & & \faIcon{check} & \faIcon{check}
& \\
eyeRead & \faIcon{check} & & \faIcon{check} & \faIcon{check}** & & \\
emov & \faIcon{check} & & \faIcon{check} & \faIcon{check} & & \\
eyetrackingR & \faIcon{check} & & \faIcon{check} & & \faIcon{check} &
\faIcon{check} \\
\end{longtable}

\end{table}

In this tutorial we demonstrate the pipeline of analysis functions
within \emph{eyetools}. The package has been designed to be simple to
use by someone with basic knowledge of data handling and analysis in R.
It should appeal to researchers who are working with raw eye data for
the first time, as well as those accustomed to working with eye data in
other environments who wish to transfer to working in an R environment.

This tutorial is separated into five distinct sections. In the first
section, we briefly describe the basic methodology of collecting eye
data in general, and with the specific dataset we use to illustrate all
the functionality of the \emph{eyetools} package. The second section
covers the process for getting data from an eye tracker into an
\emph{eyetools}-friendly format. The third section introduces the
foundational functions of the \emph{eyetools} package, from repairing
and smoothing eye data, to calculating fixations and saccades, and
detecting time spent in Areas of Interest (AOIs). The fourth section
takes the processed data and applies basic analysis techniques
commonplace in eye data research. In the fifth and final section, we
reflect on the benefits of the \emph{eyetools} package, including
contributions to open science practices, reproducibility, and providing
clarity to eye data analysis.

\subsection{Installing eyetools}\label{installing-eyetools}

\emph{eyetools} is available on CRAN and can be installed using:
\texttt{install.packages("eyetools")} . Instructions for installing
development versions can be found at the package repository:
\url{https://github.com/tombeesley/eyetools/} . Once installed, the
package can be loaded into R: \texttt{library(eyetools)}

\subsection{Preparing data for
eyetools}\label{preparing-data-for-eyetools}

Since there is a wide range of eye tracking hardware available for
researchers to use, \emph{eyetools} does not currently offer much in the
way of converting raw data from specific hardware. The
\texttt{hdf5\_to\_dataframe()} function is designed to work with output
from PsychoPy experiments connected to modern Tobii hardware and will
take this format and convert it into the simplified raw data format
required for \emph{eyetools}.

The \emph{eyetools} package has been developed primarily with the
analysis of psychology experiments in mind. To this end, many of the
functions expect a ``trial'' variable in the data, such that the
algorithms will operate over multiple trials and produce output that
retains this trial information. Similarly, data in psychology
experiments tends to come from multiple participants, and so a
participant ID column can be used (though isn't necessary), which allows
many functions to be run automatically across multiple participants. It
is also necessary to select the relevant ``periods'' of data within the
recording. It is quite typical in psychology experiments for there to be
multiple periods within a trial, e.g., fixation; stimulus presentation;
response feedback; inter-trial-interval. \emph{eyetools} does not
interpret these changes, and so it is necessary to first select the data
for the period or periods that are of interest for analysis. Analysis on
each separate period would be conducted separately using the functions
in \emph{eyetools}.

The starting point for the analysis pipeline is the preparation of the
raw eye data, which will consist of recorded samples from the
eye-tracker, with each row in the data reflecting a single time-stamped
recording. If the eye-tracker is set at 1000Hz, then consecutive
recordings will be 1 millisecond of time; at 300Hz, the recordings are
3.33 milliseconds apart. The only requirement for the time column is
that the values reflect a consistent and increasing set of values. There
is no need to specify the sampling rate, since \emph{eyetools} functions
will calculate this automatically.

\emph{eyetools} expects raw data to have the columns: x, y, time, trial,
and participant\_ID as shown in Table~\ref{tbl-data}, and missing values
in the x and y columns of the raw data should be expressed as ``NA''.

\begin{table}

{\caption{{Descriptions of the expected columns in eyetools-formatted
data}{\label{tbl-data}}}
\vspace{-20pt}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.1975}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.8025}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Column name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
x & horizontal spatial coordinate of the estimated eye position \\
y & vertical spatial coordinate of the estimated eye position \\
time & timestamp of the recording \\
trial & an index of the current trial in the data \\
participant\_ID & an index of the current participant in the data
(optional) \\
\end{longtable}

\end{table}

For many methods of recording, the eye-data will be produced in
binocular format. In such cases, \emph{eyetools} has a built in function
for combining the data: \texttt{combine\_eyes()}. This function takes a
raw data with coordinates for each eye (i.e., left\_x, right\_x,
left\_y, right\_y), and converts the data into single x and y
coordinates. By default, the function does this by taking the average of
the coordinates from the two eyes, but it is also possible to select
data from the eye with the fewest missing samples. This returns a
flattened list of participant data that has x and y variables in place
of the left\_* and right\_* variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_combined }\OtherTok{\textless{}{-}} \FunctionTok{combine\_eyes}\NormalTok{(HCL, }
                              \AttributeTok{method =} \StringTok{"average"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Working with eyetools}\label{working-with-eyetools}

\subsubsection{Counterbalanced designs}\label{counterbalanced-designs}

Many psychology experiments will position stimuli on the screen in a
counterbalanced fashion. For example, in the example data we are using,
there are two stimuli, with one of these appearing on the left of the
screen and the other on the right. In the design of the experiment, one
of these stimuli is a ``target'' and one is a ``distractor'', and the
experiment counterbalances whether these are positioned on the left or
right across trials. To provide a meaningful analysis of the data it is
necessary to standardise the data across trials so that the resulting
analyses can reflect meaningful eye gaze on relevant stimuli.

\emph{eyetools} has a built in function which allows us to transform the
x (or y) values of the stimuli to take into account a counterbalancing
variable: \texttt{conditional\_transform()}. This function currently
allows for a single-dimensional flip across either the horizontal or
vertical midline. It can be used on raw data or fixation data; we simply
need to append a column to the data to reflect the counterbalancing
variable. The result of the function is a set of data in which the x
(and/or y) position is consistent across counterbalanced conditions
(e.g., in our example, we can transform the data so that the target cue
is always on the left). This transformation is especially useful for
future visualisations and calculation of time on areas of interest. Note
that \texttt{conditional\_transform()} is another function that does not
discriminate between multi-participant and single-participant data and
so no participant\_ID parameter is required.

In our example data, the stimuli were presented on either the left or
the right side of the screen. Here we have merged the eye data with a
set of ``trial\_events'' data that describe the events on each trial. We
can apply \texttt{conditional\_transform()} and specify the relevant
column (cue\_order) that controls the counterbalancing, and the relevant
value that signals a switch of position (here ``2''). The resulting
transformation of the data will mean that the target stimulus is now
always positioned on the same side of the screen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_merged }\OtherTok{\textless{}{-}} \FunctionTok{merge}\NormalTok{(data\_combined, HCL\_behavioural) }\CommentTok{\# merges with the common variables pNum and trial}

\NormalTok{data\_counterbalanced }\OtherTok{\textless{}{-}} 
  \FunctionTok{conditional\_transform}\NormalTok{(data\_merged, }
                        \AttributeTok{flip =} \StringTok{"x"}\NormalTok{, }\CommentTok{\#flip across x midline}
                        \AttributeTok{cond\_column =} \StringTok{"cue\_order"}\NormalTok{, }\CommentTok{\# counterbalance column }
                        \AttributeTok{cond\_values =} \StringTok{"2"}\NormalTok{,}\CommentTok{\# values to flip}
                        \AttributeTok{message =} \ConstantTok{FALSE}\NormalTok{) }\CommentTok{\# suppress output message}
\end{Highlighting}
\end{Shaded}

\subsubsection{Repairing missing data and smoothing
data}\label{repairing-missing-data-and-smoothing-data}

Despite researcher's best efforts and hopes, participants are likely to
blink during data collection, resulting in observations where there are
NA values for the x and y coordinates. To mitigate this issue, the
\texttt{interpolate()} function estimates the gaze path taken, based
upon the eye coordinates before and after the missing data. There are
two methods for estimating the path, linear interpolation (``approx'',
the default setting) and cubic spline (``spline''). The default method
of linear interpolation replaces missing values with a line of constant
slope and evenly spaced coordinates reaching the existing data. The
cubic spline method applies piecewise cubic functions to enable a curve
to be calculated as opposed to a line between points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{interpolate}\NormalTok{(data\_counterbalanced, }
                    \AttributeTok{method =} \StringTok{"approx"}\NormalTok{,}
                    \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

When using \texttt{interpolate()}, a report can be requested so that a
researcher can measure how much missing data has been replaced. This
parameter changes the output format of the function and returns a list
of both the data and the report. The report can be easily accessed using
the following code:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{interpolate}\NormalTok{(data\_counterbalanced, }
            \AttributeTok{method =} \StringTok{"approx"}\NormalTok{,}
            \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{, }
            \AttributeTok{report =} \ConstantTok{TRUE}\NormalTok{)[[}\DecValTok{2}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  pNum missing_perc_before missing_perc_after
1  118          0.02314313        0.013885875
2  119          0.01214128        0.005402579
\end{verbatim}

As shown, not all missing data has been replaced, since there are
certain periods in which the missing data span a period longer than the
default setting of the ``maxgap'' parameter, which is 150ms. This
default setting is based on a typical duration for a complete blink
(\citeproc{ref-nystrom2024blink}{Nystr√∂m et al., 2024}), where the eyes
are only fully closely for 50ms
(\citeproc{ref-stern1984endogenous}{Stern et al., 1984}).

Once missing data has been fixed, a common step is to smooth the eye
data to remove particularly jerky eye movements. The function
\texttt{smoother()} reduces the noise in the data by applying a moving
averaging function. The degree of smoothing can be specified, and a plot
can be generated (using data from a randomly selected trial) to observe
how well the smoothed data fits the raw data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{smoother}\NormalTok{(data,}
                 \AttributeTok{span =}\NormalTok{ .}\DecValTok{02}\NormalTok{,}
                 \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{, }
                 \AttributeTok{plot =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{BRM_ms_files/figure-pdf/unnamed-chunk-6-1.pdf}

\subsubsection{Fixations}\label{fixations}

Once the data has been repaired and smoothed, a core step in eye data
analysis is to identify fixations
(\citeproc{ref-salvucci2000identifying}{Salvucci \& Goldberg, 2000}).
Broadly, a fixation is defined as a period in which gaze stops in a
specific location for a given amount of time. The period in which the
eyes are moving between fixations reflects a ``saccade''. As such, raw
data can be transformed into these meaningful eye data characteristics.
These different properties of eye-data have important implications for
behavioural research (see X for a review). Beyond their importance for
understanding psychological processes, transforming the data into
fixations and saccades leads to greater computational efficiency. For
example, the built in HCL data in eyetools is 479 kb, which contains
31,041 rows of data (12 trials of data). After processing the data for
fixations, the resulting data is 269 rows and can be saved as 3.8 kb
(less than 1\% the size of the raw data).

In the \emph{eyetools} package, there are two fixation algorithms
offered; the first algorithm, \texttt{fixation\_dispersion()} employs a
dispersion-based approach that uses spatial and temporal data to
determine fixations. By using a maximum dispersion range, the algorithm
looks for sufficient periods of time that the eye gaze remains within
this range and once this range is exceed, this is termed as a fixation.
The second algorithm, \texttt{fixation\_VTI()} takes advantage of the
idea that data is either a fixation or a saccade and employs a
velocity-threshold approach. It identifies data where the eye is moving
at a minimum velocity and excludes this, before applying a dispersion
check to ensure that the eye does not drift during the fixation period.
If the range is broken, a new fixation is determined. Saccades must be
of a given length to be removed, otherwise they are considered as
micro-saccades {[}@CITATION\_NEEDED\_HERE?{]}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fixations }\OtherTok{\textless{}{-}} \FunctionTok{fixation\_dispersion}\NormalTok{(data,}
                                 \AttributeTok{min\_dur =} \DecValTok{150}\NormalTok{, }\CommentTok{\# Minimum duration (in milliseconds) of fixations}
                                 \AttributeTok{disp\_tol =} \DecValTok{100}\NormalTok{, }\CommentTok{\# Maximum tolerance (in pixels) for the dispersion of values}
                                 \AttributeTok{run\_interp =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# the default is true, but we have already run interpolate()}
                                 \AttributeTok{NA\_tol =} \FloatTok{0.25}\NormalTok{, }\CommentTok{\# the proportion of NAs tolerated within a fixation window}
                                 \AttributeTok{progress =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# whether to display a progress bar or not}
                                 \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Additionally, in certain analyses it may be useful to extract the
saccades themselves. This can be achieved using the
\texttt{saccade\_VTI()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{saccades }\OtherTok{\textless{}{-}} \FunctionTok{saccade\_VTI}\NormalTok{(data, }
                        \AttributeTok{threshold =} \DecValTok{150}\NormalTok{, }
                        \AttributeTok{min\_dur =} \DecValTok{20}\NormalTok{, }
                        \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once fixations have been calculated, they can be used in conjunction
with Areas of Interest (AOIs) to determine the sequence in which the eye
enters and exits these areas, as well as the time spent in these
regions. When referring to AOIs, these often refer to the cues presented
and the outcome object. In our example, the two cues at the top of the
screen are the cues, and the outcome is at the bottom. We can define
these areas in a separate dataframe object by giving the centre point of
the AOI in x, y coordinates along with the width and height (if the AOIs
are rectangular) or just the radius (if circular).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set areas of interest}
\NormalTok{AOI\_areas }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{matrix}\NormalTok{(}\AttributeTok{nrow =} \DecValTok{3}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{4}\NormalTok{))}
\FunctionTok{colnames}\NormalTok{(AOI\_areas) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\StringTok{"y"}\NormalTok{, }\StringTok{"width\_radius"}\NormalTok{, }\StringTok{"height"}\NormalTok{)}

\NormalTok{AOI\_areas[}\DecValTok{1}\NormalTok{,] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{460}\NormalTok{, }\DecValTok{840}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{300}\NormalTok{) }\CommentTok{\# Left cue}
\NormalTok{AOI\_areas[}\DecValTok{2}\NormalTok{,] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1460}\NormalTok{, }\DecValTok{840}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{300}\NormalTok{) }\CommentTok{\# Right cue}
\NormalTok{AOI\_areas[}\DecValTok{3}\NormalTok{,] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{960}\NormalTok{, }\DecValTok{270}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{500}\NormalTok{) }\CommentTok{\# outcomes}
\end{Highlighting}
\end{Shaded}

In combination with the fixation data, the AOI information can be used
to determine the sequence of AOI entries using the \texttt{AOI\_seq()}
function. This function checks whether a fixation is detected within an
AOI, and if not, it is dropped from the output and then provides a list
of the sequence of AOI entries, along with start and end timestamps, and
the duration.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_AOI\_entry }\OtherTok{\textless{}{-}} \FunctionTok{AOI\_seq}\NormalTok{(fixations, }\AttributeTok{AOIs =}\NormalTok{ AOI\_areas,}
                          \AttributeTok{AOI\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"predictive"}\NormalTok{, }\StringTok{"non{-}predictive"}\NormalTok{, }\StringTok{"target"}\NormalTok{),}
                          \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Time spent in AOIs can also be calculated from fixations or raw data
using the \texttt{AOI\_time()} function available. This calculates the
time spent in each AOI in each trial, based on the data type given, in
our case fixation data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_AOI\_time }\OtherTok{\textless{}{-}} \FunctionTok{AOI\_time}\NormalTok{(fixations, }\AttributeTok{data\_type =} \StringTok{"fix"}\NormalTok{, }\AttributeTok{AOIs =}\NormalTok{ AOI\_areas,}
                          \AttributeTok{AOI\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"predictive"}\NormalTok{, }\StringTok{"non{-}predictive"}\NormalTok{, }\StringTok{"target"}\NormalTok{),}
                          \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If choosing to work with the raw data, there is also the option of using
\texttt{AOI\_time\_binned()} which allows for the trials to be split
into bins of a given length, and the time spent in AOIs calculated as a
result.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_AOI\_time\_binned }\OtherTok{\textless{}{-}} \FunctionTok{AOI\_time\_binned}\NormalTok{(data, }\AttributeTok{AOIs =}\NormalTok{ AOI\_areas,}
                                        \AttributeTok{AOI\_names =} \FunctionTok{c}\NormalTok{(}\StringTok{"predictive"}\NormalTok{, }\StringTok{"non{-}predictive"}\NormalTok{, }\StringTok{"target"}\NormalTok{),}
                                        \AttributeTok{bin\_length =} \DecValTok{100}\NormalTok{,}
                                        \AttributeTok{max\_time =} \DecValTok{2000}\NormalTok{, }\CommentTok{\#in milliseconds}
                                        \AttributeTok{participant\_ID =} \StringTok{"pNum"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Visualisations made easy}\label{visualisations-made-easy}

When working with eye data, it can be beneficial for the researcher to
familiarise themselves with the dataset. Visualising the data through
graphics can help to identify meaningful patterns that are obscured when
relying on statistical analyses alone
(\citeproc{ref-kabacoffActionThirdEdition2022}{Kabacoff, 2022}).
Graphics are also very effective at conveying information in a way that
is easily grasped by a diverse audience. eyetools offers a selection of
in-built plotting functions that work with data at most stages of
processing. These plots are designed to aid in the researcher's
processing and data analysis.

The \texttt{plot\_AOI\_growth()} function offers the representation of
how an individual (on a single trial) spends their time looking at the
different AOIs. This can be useful to see how AOIs are interacted with
over time, and this can be presented as either a cumulative over time,
or as a proportion of the time spent in the trial.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot absolute and then proportional}
\FunctionTok{plot\_AOI\_growth}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data, }
                \AttributeTok{AOIs =}\NormalTok{ HCL\_AOIs, }
                \AttributeTok{type =} \StringTok{"abs"}\NormalTok{, }
                \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\FunctionTok{plot\_AOI\_growth}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data, }
                \AttributeTok{AOIs =}\NormalTok{ HCL\_AOIs, }
                \AttributeTok{type =} \StringTok{"prop"}\NormalTok{, }
                \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\caption{\label{fig-growth}Examples of the absolute and proportional
time plots from \texttt{plot\_AOI\_growth()}}

\begin{minipage}{0.50\linewidth}

\subcaption{\label{fig-abs}}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-abs-1.pdf}

}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\subcaption{\label{fig-prop}}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-prop-1.pdf}

}

\end{minipage}%

\end{figure}%

A heatmap of eye gaze positions can be generated using
\texttt{plot\_heatmap()} which takes raw data as an input. As a
function, and unlike many of the processing steps, it does not
differentiate between trials or participants and plots any coordinate
data it is given. This behaviour is allowed as the heatmap offers an
excellent and fast ``sanity check'' that participants were, overall,
looking at the expected areas of the experiment screen during the
trials. As can be seen in Figure Figure~\ref{fig-heatmap}, we can be
reassured that participants do indeed spend most of their time looking
at the stimuli on screen rather than in the empty space.
\texttt{plot\_heatmap()} also allows for the modification of the amount
of data displayed, using the \texttt{alpha\_control} parameter. By
decreasing \texttt{alpha\_control} in Figure
Figure~\ref{fig-heatmap-alpha-update}, we gain more visualised
information, and we can still see that most of the data is kept within
the stimuli and saccades between these areas.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_heatmap}\NormalTok{(data, }\AttributeTok{bg\_image =} \StringTok{"images/HCL\_sample\_image.jpg"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\caption{\label{fig-heatmap}A heatmap overlaid upon a sample stimuli
image demonstrating where the participants looked most overall trials}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-heatmap-1.pdf}

}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_heatmap}\NormalTok{(data, }\AttributeTok{alpha\_control =}\NormalTok{ .}\DecValTok{001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\caption{\label{fig-heatmap-alpha-update}A heatmap overlaid upon a
sample stimuli image demonstrating where the participants looked most
overall trials}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-heatmap-alpha-update-1.pdf}

}

\end{figure}%

The \texttt{plot\_seq()} function allows for the plotting of raw data to
visualise the gaze pattern from a single trial and where the gaze fell
on the screen across the entire trial. Figure~\ref{fig-seq} offers an
example trial split into time bins of 5000ms. This plot shows the time
dimension as a change in colour that overlaps older data. This plot
serves as a useful check, similar to \texttt{plot\_heatmap()}, as to
where the eyes spent their time, but \texttt{plot\_seq()} has the
benefit of showing the time dimension compared to a simple heatmap.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot raw data with bins}
\FunctionTok{plot\_seq}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{pNum }\SpecialCharTok{==} \DecValTok{118}\NormalTok{,], }
         \AttributeTok{AOIs =}\NormalTok{ HCL\_AOIs,  }
         \AttributeTok{bin\_time =} \DecValTok{5000}\NormalTok{, }
         \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\caption{\label{fig-seq}The output from plot\_seq() with included AOIs
and time binned into 5 second sections}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-seq-1.pdf}

}

\end{figure}%

The final plotting function in eyetools is \texttt{plot\_spatial()}.
This can plot raw data, fixations, and saccades, either separately or in
combination. \texttt{plot\_spatial()} plots the location of the eye gaze
of a trial, and when given raw data is very similar to the output of
\texttt{plot\_seq()}, when using fixation data, then an additional
parameter can be used to label the fixations in their temporal order,
enabling a better presentation of how fixations arise. Finally,
providing saccade data allows for the length and direction of saccades
to be presented.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_spatial}\NormalTok{(}\AttributeTok{raw\_data =}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{pNum }\SpecialCharTok{==} \DecValTok{118}\NormalTok{,], }
             \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\CommentTok{\# plot just fixation data together}
\FunctionTok{plot\_spatial}\NormalTok{(}\AttributeTok{fix\_data =}\NormalTok{ fixations[fixations}\SpecialCharTok{$}\NormalTok{pNum }\SpecialCharTok{==} \DecValTok{118}\NormalTok{,], }
             \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\CommentTok{\#plot saccades}
\FunctionTok{plot\_spatial}\NormalTok{(}\AttributeTok{sac\_data =}\NormalTok{ saccades[saccades}\SpecialCharTok{$}\NormalTok{pNum }\SpecialCharTok{==} \DecValTok{118}\NormalTok{,], }
             \AttributeTok{trial\_number =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\caption{\label{fig-spatial}The three plot types that can be created
using \texttt{plot\_spatial()}}

\begin{minipage}{0.33\linewidth}

\subcaption{\label{fig-spatial-raw}}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-spatial-raw-1.pdf}

}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\subcaption{\label{fig-spatial-fix}}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-spatial-fix-1.pdf}

}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\subcaption{\label{fig-spatial-sac}}

\centering{

\includegraphics{BRM_ms_files/figure-pdf/fig-spatial-sac-1.pdf}

}

\end{minipage}%

\end{figure}%

\subsection{eyetools assumptions}\label{eyetools-assumptions}

As with any data processing or analysis, there are certain assumptions
made when developing the eyetools package. Some of these are built into
the package directly, either as errors or warnings, such as the
assumption that data is ordered by participant ID (if present) and
trial, and some are not built in because they would limit the
flexibility of the package functionality. One built-in assumption is the
handling of missing data. eyetools expects track loss to be represented
as NA within the data, and so any system that provides a different
convention for recording track loss needs to be changed prior to using
eyetools functions.

During development, eyetools was tested using data collected from a
Tobii Pro Spectrum eye tracker recording at 300Hz. Screen resolutions
were constant at 1080x1920 pixels, and the timestamps were recorded in
milliseconds. Whilst most of the functions were designed to work with
any hardware provided the data is formatted to eyetools expectations
(with the exception of \texttt{hdf5\_to\_df()} and
\texttt{hdf5\_get\_event()} as these convert Tobii data), as well as not
relying on specific frequencies or resolutions (either through the
function behaviour, or by supplying parameters for specificity),
eyetools has not been tested on a diverse set of datasets.

Some default behaviours are in-built but are easily overridden such as
parameters for resolution in the plotting functions. Similarly
\texttt{saccade\_VTI()} and \texttt{fixation\_VTI()} were tested with
300Hz data. For these functions, as the frequency increases, the
relative saccadic velocities will be lower meaning that the thresholds
need to be reduced. This is important to note when working with data
that is not recorded at 300Hz. To circumvent the potential issue of
sample rates being an issue, by default functions that require a sample
rate will deduce the frequency from the data.

\section{Analysing eye data}\label{analysing-eye-data}

@tom

\section{Discussion}\label{discussion}

In the present tutorial, we began by identifying the current gap in
available tools for working with eye data in open-science pipelines. We
then provided an overview of the general data collection process
required for eye tracking research, before detailing the conversion of
raw eye data into a useable \emph{eyetools} format. We then covered the
entire processing pipeline using functions available in the
\emph{eyetools} package that included the repairing and normalising the
data, and the detection of events such as fixations, saccades, and AOI
entries. @SOMETHING\_ON\_THE\_ANALYSIS\_GOES\_HERE.

From a practical perspective, this tutorial offers a step-by-step
walkthrough for handling eye data using R for open-science, reproducible
purposes. It provides a pipeline that can be relied upon by novices
looking to work with eye data, as well as offering new functions and
tools for experienced researchers. By enabling the processing and
analysis of data in a single R environment it also helps to speed up
data analysis.

\subsection{Advantages of Open-Source
Tools}\label{advantages-of-open-source-tools}

eyetools offers an open-source toolset that holds no hidden nor
proprietary functionality. The major benefits of open-source tools are
extensive, but the main ones include the ability to explore and engage
with the underlying functions to ensure that

A collaborative community - with open source tools, if an unmet need is
identified, then the community can work to provide a solution.

\subsection{Good Science Practices with
eyetools}\label{good-science-practices-with-eyetools}

Creating save points (like having processed raw data, and then
post-fixation calculation). Reduces the need to completely rework
workflows if an issue is detected as save points can be used to ensure
that computationally-intense or time-heavy processes are conducted as
infrequently as possible.

\section{Data Availability}\label{data-availability}

The data required for reproducing this tutorial is available at: @URL. A
condensed version of the dataset (starting with the
\texttt{combine\_eyes()} function) is a dataset in the \emph{eyetools}
package called HCL.

\section{Code Availability}\label{code-availability}

The code used in this tutorial is available in the reproducible
manuscript file available at:(IF STORING IN GITHUB, THEN WE NEED TO
CREATE A ZENODO SNAPSHOT FOR A DOI RATHER THAN JUST A GITHUB LINK)

\section{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-duchowski2017eye}
Duchowski, A. T., \& Duchowski, A. T. (2017). \emph{Eye tracking
methodology: Theory and practice}. Springer.

\bibitem[\citeproctext]{ref-kabacoffActionThirdEdition2022}
Kabacoff, R. I. (2022). \emph{R in action: Data analysis and graphics
with r and tidyverse}. Simon; Schuster.

\bibitem[\citeproctext]{ref-nystrom2024blink}
Nystr√∂m, M., Andersson, R., Niehorster, D. C., Hessels, R. S., \& Hooge,
I. T. (2024). What is a blink? Classifying and characterizing blinks in
eye openness signals. \emph{Behavior Research Methods}, 1--20.

\bibitem[\citeproctext]{ref-salvucci2000identifying}
Salvucci, D. D., \& Goldberg, J. H. (2000). Identifying fixations and
saccades in eye-tracking protocols. \emph{Proceedings of the 2000
Symposium on Eye Tracking Research \& Applications}, 71--78.

\bibitem[\citeproctext]{ref-stern1984endogenous}
Stern, J. A., Walrath, L. C., \& Goldstein, R. (1984). The endogenous
eyeblink. \emph{Psychophysiology}, \emph{21}(1), 22--33.

\end{CSLReferences}






\end{document}
